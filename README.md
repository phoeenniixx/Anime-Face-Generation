# Anime-Face-Generation

Anime face generation using DCGAN (Deep Convolutional Generative Adversarial Network) involves training a generator and discriminator model to generate realistic anime faces. The generator creates synthetic anime faces, while the discriminator learns to distinguish between real and generated faces. 

Images generated at 0 epoch
![WhatsApp Image 2024-03-10 at 04 09 11_74f698e4](https://github.com/phoeenniixx/Anime-Face-Generation/assets/116151399/b5c65e8e-d757-4262-b293-1a9e0e2ae223)

Final images:
![image](https://github.com/phoeenniixx/Anime-Face-Generation/assets/116151399/b3b843d7-7ee1-4949-8d84-5ad828728b37)

![image](https://github.com/phoeenniixx/Anime-Face-Generation/assets/116151399/33a45961-cce6-4095-a343-de8a685b6e49)





1. Generator:

    The generator takes random noise as input and transforms it into an image.
    It typically consists of transposed convolutional layers (also known as deconvolutional layers) to upsample the input noise.
    The goal is to learn to generate realistic images that resemble anime faces.
   
2. Discriminator:

    The discriminator is a binary classifier that evaluates whether an input image is real (an actual anime face from the dataset) or fake (generated by the generator).
    It consists of convolutional layers to downsample the input image and make a binary classification.
    The discriminator aims to distinguish between real and generated images.
   
3. Training Process:

    During training, the generator and discriminator are trained simultaneously in a competitive manner.
    The generator aims to generate images that are indistinguishable from real anime faces, while the discriminator learns to improve its ability to differentiate between real and fake images.
   
4. Loss Functions:

    The generator is trained to minimize the binary cross-entropy loss, fooling the discriminator into thinking generated images are real.
    The discriminator is trained to minimize its own binary cross-entropy loss, correctly classifying real and fake images.
   
5. Hyperparameters:

   The hyperparameters include the learning rates for both the generator and discriminator, the noise dimension fed to the generator, and the architecture of both networks.
   Batch normalization and leaky ReLU activations are commonly used in DCGANs to stabilize and improve training.
  
6. Dataset:

   A dataset of anime faces is used for training. The quality and diversity of the dataset play a crucial role in the generator's ability to create realistic and diverse anime faces.
   Dataset used: <a href = "https://www.kaggle.com/datasets/splcher/animefacedataset"> Anime Face Dataset</a>


## <a href = "https://colab.research.google.com/drive/1ZCds-bR0EBH7x8nFI2NbdDaOz7-Bppmn?usp=sharing"> Google Colab Link</a>
